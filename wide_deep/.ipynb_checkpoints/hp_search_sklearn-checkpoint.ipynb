{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta0\n",
      "sys.version_info(major=3, minor=7, micro=0, releaselevel='final', serial=0)\n",
      "matplotlib 3.0.3\n",
      "numpy 1.16.0\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0-beta0\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
      "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
      "         3.78800000e+01, -1.22230000e+02],\n",
      "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
      "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
      "         3.78600000e+01, -1.22220000e+02],\n",
      "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
      "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
      "         3.78500000e+01, -1.22240000e+02],\n",
      "       [ 5.64310000e+00,  5.20000000e+01,  5.81735160e+00,\n",
      "         1.07305936e+00,  5.58000000e+02,  2.54794521e+00,\n",
      "         3.78500000e+01, -1.22250000e+02],\n",
      "       [ 3.84620000e+00,  5.20000000e+01,  6.28185328e+00,\n",
      "         1.08108108e+00,  5.65000000e+02,  2.18146718e+00,\n",
      "         3.78500000e+01, -1.22250000e+02]])\n",
      "array([4.526, 3.585, 3.521, 3.413, 3.422])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(housing.data[0:5])\n",
    "pprint.pprint(housing.target[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all,x_test,y_train_all,y_test = train_test_split(housing.data,housing.target,random_state=7)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(housing.data,housing.target,random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "x_train_std = std.fit_transform(x_train)\n",
    "x_test_std = std.transform(x_test)\n",
    "x_valid_std = std.transform(x_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15480 samples, validate on 5160 samples\n",
      "Epoch 1/10\n",
      "15480/15480 [==============================] - 0s 26us/sample - loss: 1.1778 - val_loss: 1.2153\n",
      "Epoch 2/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.6470 - val_loss: 0.6587\n",
      "Epoch 3/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.5501 - val_loss: 0.5373\n",
      "Epoch 4/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.5140 - val_loss: 0.5486\n",
      "Epoch 5/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.4858 - val_loss: 0.4896\n",
      "Epoch 6/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.4741 - val_loss: 0.5126\n",
      "Epoch 7/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.4674 - val_loss: 0.5828\n",
      "Epoch 8/10\n",
      "15480/15480 [==============================] - 0s 20us/sample - loss: 0.4567 - val_loss: 0.4899\n",
      "Epoch 9/10\n",
      "15480/15480 [==============================] - 0s 19us/sample - loss: 0.4415 - val_loss: 0.4812\n",
      "Epoch 10/10\n",
      "15480/15480 [==============================] - 0s 21us/sample - loss: 0.4430 - val_loss: 0.4457\n"
     ]
    }
   ],
   "source": [
    "# 1.转化为sklean的model\n",
    "# 2.定义参数集合\n",
    "# 3.搜索参数 \n",
    "\n",
    "\"\"\"创建模型的函数\"\"\"\n",
    "def build_model(hidden_layers = 1,\n",
    "                layer_size = 30,            \n",
    "                learning_rate = 3e-3):\n",
    "    \n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(layer_size,activation=\"relu\",\n",
    "                                 input_shape=x_train.shape[1:]))\n",
    "    \n",
    "    # model.add(keras.layers.Dense(layer_size, activation='relu',\n",
    "    #                          input_shape=x_train.shape[1:]))\n",
    "    \n",
    "    for _ in range(hidden_layers-1):\n",
    "        model.add(keras.layers.Dense(layer_size=layer_size,activation=\"relu\"))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss='mse',optimizer=optimizer)\n",
    "    return model\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]\n",
    "\n",
    "# callbacks = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]\n",
    "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model)\n",
    "history = sklearn_model.fit(x_train_std,y_train,epochs = 10,\n",
    "                  validation_data = (x_valid_std,y_valid),\n",
    "                 callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "d:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-07d17e8ef7b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m random_search_cv.fit(x_train_std,y_train,epochs = 100,\n\u001b[0;32m     16\u001b[0m          \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_valid_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m          callbacks = callbacks)\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m           **self.filter_sk_params(self.build_fn.__call__))\n\u001b[0;32m    156\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "\u001b[1;32m<ipython-input-7-17442fc02f11>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(hidden_layers, layer_size, learning_rate)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "# from scipy.stats import reciprocal\n",
    "\n",
    "# param_distribution = {\n",
    "#     \"hidden_layers\":[1, 2, 3, 4],\n",
    "#     \"layer_size\": np.arange(1, 100),\n",
    "#     \"learning_rate\": reciprocal(1e-4, 1e-2),\n",
    "# }\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# random_search_cv = RandomizedSearchCV(sklearn_model,\n",
    "#                           param_distribution,\n",
    "#                           n_iter=10,\n",
    "#                           n_jobs = 1)\n",
    "# random_search_cv.fit(x_train_std,y_train,epochs = 100,\n",
    "#          validation_data = (x_valid_std,y_valid),\n",
    "#          callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10320 samples, validate on 5160 samples\n",
      "Epoch 1/100\n",
      "10320/10320 [==============================] - ETA: 0s - loss: 4.964 - 0s 30us/sample - loss: 4.8646 - val_loss: 3.6790\n",
      "Epoch 2/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 2.8461 - val_loss: 2.5287\n",
      "Epoch 3/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 2.0119 - val_loss: 1.9422\n",
      "Epoch 4/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 1.5850 - val_loss: 1.5724\n",
      "Epoch 5/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 1.3259 - val_loss: 1.3275\n",
      "Epoch 6/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 1.1558 - val_loss: 1.1531\n",
      "Epoch 7/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 1.0393 - val_loss: 1.0347\n",
      "Epoch 8/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.9593 - val_loss: 0.9516\n",
      "Epoch 9/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.9038 - val_loss: 0.8955\n",
      "Epoch 10/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.8646 - val_loss: 0.8574\n",
      "Epoch 11/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.8361 - val_loss: 0.8302\n",
      "Epoch 12/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.8145 - val_loss: 0.8099\n",
      "Epoch 13/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7977 - val_loss: 0.7940\n",
      "Epoch 14/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.7838 - val_loss: 0.7814\n",
      "Epoch 15/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7721 - val_loss: 0.7705\n",
      "Epoch 16/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.7618 - val_loss: 0.7612\n",
      "Epoch 17/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7526 - val_loss: 0.7527\n",
      "Epoch 18/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7441 - val_loss: 0.7448\n",
      "Epoch 19/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7362 - val_loss: 0.7375\n",
      "Epoch 20/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7287 - val_loss: 0.7305\n",
      "Epoch 21/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7217 - val_loss: 0.7239\n",
      "Epoch 22/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7149 - val_loss: 0.7175\n",
      "Epoch 23/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7085 - val_loss: 0.7114\n",
      "Epoch 24/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7023 - val_loss: 0.7055\n",
      "Epoch 25/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6962 - val_loss: 0.6999\n",
      "Epoch 26/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6904 - val_loss: 0.6944\n",
      "Epoch 27/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6848 - val_loss: 0.6891\n",
      "Epoch 28/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6792 - val_loss: 0.6839\n",
      "Epoch 29/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6738 - val_loss: 0.6789\n",
      "Epoch 30/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6686 - val_loss: 0.6741\n",
      "Epoch 31/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6634 - val_loss: 0.6695\n",
      "Epoch 32/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6584 - val_loss: 0.6648\n",
      "Epoch 33/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6535 - val_loss: 0.6602\n",
      "Epoch 34/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6487 - val_loss: 0.6557\n",
      "Epoch 35/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6439 - val_loss: 0.6513\n",
      "Epoch 36/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6393 - val_loss: 0.6470\n",
      "Epoch 37/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6348 - val_loss: 0.6427\n",
      "Epoch 38/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6303 - val_loss: 0.6387\n",
      "Epoch 39/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6260 - val_loss: 0.6345\n",
      "Epoch 40/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6218 - val_loss: 0.6305\n",
      "Epoch 41/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6176 - val_loss: 0.6264\n",
      "Epoch 42/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6136 - val_loss: 0.6225\n",
      "Epoch 43/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6097 - val_loss: 0.6187\n",
      "Epoch 44/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6058 - val_loss: 0.6150\n",
      "Epoch 45/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6021 - val_loss: 0.6113\n",
      "Epoch 46/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5984 - val_loss: 0.6077\n",
      "Epoch 47/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5947 - val_loss: 0.6042\n",
      "Epoch 48/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5912 - val_loss: 0.6008\n",
      "Epoch 49/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5878 - val_loss: 0.5974\n",
      "Epoch 50/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5844 - val_loss: 0.5941\n",
      "Epoch 51/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5811 - val_loss: 0.5909\n",
      "Epoch 52/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5779 - val_loss: 0.5878\n",
      "Epoch 53/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5747 - val_loss: 0.5847\n",
      "Epoch 54/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5716 - val_loss: 0.5817\n",
      "Epoch 55/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5685 - val_loss: 0.5787\n",
      "Epoch 56/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5656 - val_loss: 0.5757\n",
      "Epoch 57/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5627 - val_loss: 0.5729\n",
      "Epoch 58/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5598 - val_loss: 0.5700\n",
      "Epoch 59/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5570 - val_loss: 0.5673\n",
      "Epoch 60/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5542 - val_loss: 0.5646\n",
      "Epoch 61/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5515 - val_loss: 0.5620\n",
      "Epoch 62/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5488 - val_loss: 0.5594\n",
      "Epoch 63/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5462 - val_loss: 0.5569\n",
      "Epoch 64/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5437 - val_loss: 0.5544\n",
      "Epoch 65/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5413 - val_loss: 0.5521\n",
      "Epoch 66/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5389 - val_loss: 0.5498\n",
      "Epoch 67/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5366 - val_loss: 0.5476\n",
      "Epoch 68/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5343 - val_loss: 0.5457\n",
      "Epoch 69/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5322 - val_loss: 0.5434\n",
      "Epoch 70/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5300 - val_loss: 0.5413\n",
      "Epoch 71/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5279 - val_loss: 0.5393\n",
      "Epoch 72/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5259 - val_loss: 0.5374\n",
      "Epoch 73/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5239 - val_loss: 0.5354\n",
      "Epoch 74/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5220 - val_loss: 0.5336\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5202 - val_loss: 0.5318\n",
      "Epoch 76/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.5183 - val_loss: 0.5301\n",
      "Epoch 77/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.5166 - val_loss: 0.5284\n",
      "5160/5160 [==============================] - 0s 9us/sample - loss: 0.5092\n",
      "Train on 10320 samples, validate on 5160 samples\n",
      "Epoch 1/100\n",
      "10320/10320 [==============================] - 0s 29us/sample - loss: 4.4462 - val_loss: 3.5259\n",
      "Epoch 2/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 2.6034 - val_loss: 2.2610\n",
      "Epoch 3/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 1.7381 - val_loss: 1.5946\n",
      "Epoch 4/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 1.2970 - val_loss: 1.2445\n",
      "Epoch 5/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 1.0623 - val_loss: 1.0472\n",
      "Epoch 6/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.9318 - val_loss: 0.9325\n",
      "Epoch 7/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.8566 - val_loss: 0.8654\n",
      "Epoch 8/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.8116 - val_loss: 0.8237\n",
      "Epoch 9/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7824 - val_loss: 0.7959\n",
      "Epoch 10/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.7622 - val_loss: 0.7767\n",
      "Epoch 11/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7469 - val_loss: 0.7621\n",
      "Epoch 12/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.7345 - val_loss: 0.7502\n",
      "Epoch 13/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7239 - val_loss: 0.7399\n",
      "Epoch 14/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.7143 - val_loss: 0.7306\n",
      "Epoch 15/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.7056 - val_loss: 0.7219\n",
      "Epoch 16/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6973 - val_loss: 0.7140\n",
      "Epoch 17/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6896 - val_loss: 0.7064\n",
      "Epoch 18/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6822 - val_loss: 0.6991\n",
      "Epoch 19/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6751 - val_loss: 0.6921\n",
      "Epoch 20/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6682 - val_loss: 0.6855\n",
      "Epoch 21/100\n",
      "10320/10320 [==============================] - 0s 23us/sample - loss: 0.6616 - val_loss: 0.6790\n",
      "Epoch 22/100\n",
      "10320/10320 [==============================] - 0s 22us/sample - loss: 0.6553 - val_loss: 0.6728\n",
      "Epoch 23/100\n",
      "   32/10320 [..............................] - ETA: 0s - loss: 0.8503"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "# f(x) = 1/(x*log(b/a)) a <= x <= b\n",
    "\n",
    "param_distribution = {\n",
    "    \"hidden_layers\":[1, 2, 3, 4],\n",
    "    \"layer_size\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(1e-4, 1e-2),\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(sklearn_model,\n",
    "                                      param_distribution,\n",
    "                                      n_iter = 10,\n",
    "                                      # cv = 3,\n",
    "                                      n_jobs = 1)\n",
    "random_search_cv.fit(x_train_std, y_train, epochs = 100,\n",
    "                     validation_data = (x_valid_std, y_valid),\n",
    "                     callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
